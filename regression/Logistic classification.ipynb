{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\abcd4\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\compat\\v2_compat.py:65: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Data\n",
    "x_data = [[1,2], [2,3], [3,1], [4,3], [5,3], [6,2]]\n",
    "y_data = [[0], [0], [0], [1], [1], [1]]\n",
    "#0 : fail, 1 : pass\n",
    "\n",
    "#placeholders for a tensor that will be always fed.\n",
    "#pay attention to the shape \n",
    "x = tf.placeholder(tf.float32, shape = [None, 2])\n",
    "y = tf.placeholder(tf.float32, shape = [None, 1]) \n",
    "w = tf.Variable(tf.random_normal([2,1]), name = 'weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name = 'bias')\n",
    "\n",
    "#Hypothesis using sigmoid : tf.div(1., 1. + tf.exp(tf.matmul(x,w) + b))\n",
    "hypothesis = tf.sigmoid(tf.matmul(x, w) + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ H(x) = \\frac{1}{1+e^{-(w^T)x}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cost/loss function\n",
    "cost = -tf.reduce_mean(y * tf.log(hypothesis) + (1 - y) * tf.log(1-hypothesis))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ cost(w) = -\\frac{1}{m}\\sum_{}y\\log({H(x)})+(1-y)(\\log({1-H(x)}) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tf.train.GradientDescentOptimizer(learning_rate = 0.01).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ w:= w-\\alpha\\frac{\\partial}{\\partial w}cost(w) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy computation\n",
    "#True if hypothesis > 0.5 else Flase\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype = tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, y), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.6405548\n",
      "200 0.58545345\n",
      "400 0.53522277\n",
      "600 0.50363165\n",
      "800 0.48006663\n",
      "1000 0.4604895\n",
      "1200 0.44318902\n",
      "1400 0.42737356\n",
      "1600 0.41264883\n",
      "1800 0.3988042\n",
      "2000 0.38571766\n",
      "2200 0.37331235\n",
      "2400 0.3615341\n",
      "2600 0.350341\n",
      "2800 0.33969793\n",
      "3000 0.32957378\n",
      "3200 0.3199397\n",
      "3400 0.31076866\n",
      "3600 0.30203545\n",
      "3800 0.29371563\n",
      "4000 0.28578612\n",
      "4200 0.278225\n",
      "4400 0.2710115\n",
      "4600 0.26412594\n",
      "4800 0.2575499\n",
      "5000 0.25126567\n",
      "5200 0.24525702\n",
      "5400 0.23950829\n",
      "5600 0.23400487\n",
      "5800 0.2287332\n",
      "6000 0.22368036\n",
      "6200 0.21883427\n",
      "6400 0.2141837\n",
      "6600 0.20971812\n",
      "6800 0.20542753\n",
      "7000 0.20130265\n",
      "7200 0.19733477\n",
      "7400 0.19351566\n",
      "7600 0.1898377\n",
      "7800 0.18629362\n",
      "8000 0.18287666\n",
      "8200 0.17958063\n",
      "8400 0.17639928\n",
      "8600 0.17332725\n",
      "8800 0.17035918\n",
      "9000 0.16749017\n",
      "9200 0.16471542\n",
      "9400 0.16203062\n",
      "9600 0.1594316\n",
      "9800 0.1569145\n",
      "10000 0.15447561\n",
      "\n",
      " Hypothesis:  [[0.03286268]\n",
      " [0.16162698]\n",
      " [0.31486684]\n",
      " [0.7768509 ]\n",
      " [0.9366834 ]\n",
      " [0.97920334]] \n",
      " Correct(y):  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]] \n",
      " Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "#Train the model\n",
    "\n",
    "#Launch graph\n",
    "with tf.Session() as sess:\n",
    "    #Initialize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(10001):\n",
    "        cost_val, _ = sess.run([cost, train], feed_dict={x:x_data, y:y_data})\n",
    "        if step % 200 == 0 :\n",
    "            print(step, cost_val)\n",
    "    \n",
    "    #Accuracy report\n",
    "    h, c, a  = sess.run([hypothesis, predicted, accuracy],\n",
    "                       feed_dict={x:x_data, y:y_data})\n",
    "    print('\\n Hypothesis: ', h, '\\n Correct(y): ', c, '\\n Accuracy: ', a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying diabetes\n",
    "It is example to apply above model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abcd4\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py:678: UserWarning: Duplicate names specified. This will raise an error in the future.\n",
      "  return _read(filepath_or_buffer, kwds)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>data.1</th>\n",
       "      <th>data.2</th>\n",
       "      <th>data.3</th>\n",
       "      <th>data.4</th>\n",
       "      <th>data.5</th>\n",
       "      <th>data.6</th>\n",
       "      <th>data.7</th>\n",
       "      <th>diabets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.294118</td>\n",
       "      <td>0.487437</td>\n",
       "      <td>0.180328</td>\n",
       "      <td>-0.292929</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001490</td>\n",
       "      <td>-0.531170</td>\n",
       "      <td>-0.033333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.882353</td>\n",
       "      <td>-0.145729</td>\n",
       "      <td>0.081967</td>\n",
       "      <td>-0.414141</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.207153</td>\n",
       "      <td>-0.766866</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.058824</td>\n",
       "      <td>0.839196</td>\n",
       "      <td>0.049180</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.305514</td>\n",
       "      <td>-0.492741</td>\n",
       "      <td>-0.633333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.882353</td>\n",
       "      <td>-0.105528</td>\n",
       "      <td>0.081967</td>\n",
       "      <td>-0.535354</td>\n",
       "      <td>-0.777778</td>\n",
       "      <td>-0.162444</td>\n",
       "      <td>-0.923997</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.376884</td>\n",
       "      <td>-0.344262</td>\n",
       "      <td>-0.292929</td>\n",
       "      <td>-0.602837</td>\n",
       "      <td>0.284650</td>\n",
       "      <td>0.887276</td>\n",
       "      <td>-0.600000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       data    data.1    data.2    data.3    data.4    data.5    data.6  \\\n",
       "0 -0.294118  0.487437  0.180328 -0.292929  0.000000  0.001490 -0.531170   \n",
       "1 -0.882353 -0.145729  0.081967 -0.414141  0.000000 -0.207153 -0.766866   \n",
       "2 -0.058824  0.839196  0.049180  0.000000  0.000000 -0.305514 -0.492741   \n",
       "3 -0.882353 -0.105528  0.081967 -0.535354 -0.777778 -0.162444 -0.923997   \n",
       "4  0.000000  0.376884 -0.344262 -0.292929 -0.602837  0.284650  0.887276   \n",
       "\n",
       "     data.7  diabets  \n",
       "0 -0.033333        0  \n",
       "1 -0.666667        1  \n",
       "2 -0.633333        0  \n",
       "3  0.000000        1  \n",
       "4 -0.600000        0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data-03-diabetes.csv', names = ['data','data','data','data','data','data','data','data','diabets'] )\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**It is unknown dataset but last column is a measure of whether or not diabetes is present.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = np.loadtxt('data-03-diabetes.csv', delimiter = ',', dtype = np.float32)\n",
    "x_data = xy[:,0:-1]\n",
    "y_data = xy[:, [-1]]\n",
    "#read csv as numpy and slicing last column and others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#placeholders for a tensor that will be always fed.\n",
    "x = tf.placeholder(tf.float32, shape=[None, 8]) #important to know how is data's shape\n",
    "y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "w = tf.Variable(tf.random_normal([8,1]), name = 'weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name = 'bias')\n",
    "\n",
    "#Hyphthesis using above sigmoid\n",
    "hypothesis = tf.sigmoid(tf.matmul(x, w) + b)\n",
    "\n",
    "#cost/loss function\n",
    "cost = -tf.reduce_mean(y * tf.log(hypothesis) + (1 - y) * tf.log(1-hypothesis))\n",
    "\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate = 0.01).minimize(cost)\n",
    "\n",
    "#Accuracy computation\n",
    "#True if hypothesis > 0.5 else Flase\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype = tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, y), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.3040094\n",
      "200 0.84420234\n",
      "400 0.7493984\n",
      "600 0.71506697\n",
      "800 0.6916189\n",
      "1000 0.6717488\n",
      "1200 0.6541473\n",
      "1400 0.63843286\n",
      "1600 0.6243828\n",
      "1800 0.61181223\n",
      "2000 0.60055476\n",
      "2200 0.5904605\n",
      "2400 0.5813955\n",
      "2600 0.5732403\n",
      "2800 0.5658891\n",
      "3000 0.5592489\n",
      "3200 0.55323803\n",
      "3400 0.5477845\n",
      "3600 0.5428258\n",
      "3800 0.5383068\n",
      "4000 0.5341794\n",
      "4200 0.53040135\n",
      "4400 0.5269358\n",
      "4600 0.5237502\n",
      "4800 0.5208162\n",
      "5000 0.51810855\n",
      "5200 0.5156051\n",
      "5400 0.5132863\n",
      "5600 0.51113486\n",
      "5800 0.5091354\n",
      "6000 0.5072741\n",
      "6200 0.5055388\n",
      "6400 0.5039187\n",
      "6600 0.50240415\n",
      "6800 0.500986\n",
      "7000 0.49965674\n",
      "7200 0.49840903\n",
      "7400 0.49723673\n",
      "7600 0.49613395\n",
      "7800 0.49509528\n",
      "8000 0.49411613\n",
      "8200 0.49319226\n",
      "8400 0.4923195\n",
      "8600 0.49149445\n",
      "8800 0.4907136\n",
      "9000 0.4899741\n",
      "9200 0.48927316\n",
      "9400 0.4886083\n",
      "9600 0.487977\n",
      "9800 0.48737723\n",
      "10000 0.48680708\n",
      "\n",
      " Hypothesis:  [[0.41454107]\n",
      " [0.9218278 ]\n",
      " [0.22302344]\n",
      " [0.9411807 ]\n",
      " [0.11427283]\n",
      " [0.7359735 ]\n",
      " [0.93443143]\n",
      " [0.5965813 ]\n",
      " [0.2759971 ]\n",
      " [0.4987421 ]\n",
      " [0.6747928 ]\n",
      " [0.17949992]\n",
      " [0.17915997]\n",
      " [0.36292347]\n",
      " [0.69171107]\n",
      " [0.42277116]\n",
      " [0.7037822 ]\n",
      " [0.8388748 ]\n",
      " [0.8038246 ]\n",
      " [0.54743016]\n",
      " [0.61154073]\n",
      " [0.11487609]\n",
      " [0.69213164]\n",
      " [0.72652733]\n",
      " [0.3573875 ]\n",
      " [0.94237983]\n",
      " [0.64763725]\n",
      " [0.60084337]\n",
      " [0.7000036 ]\n",
      " [0.42865703]\n",
      " [0.9617226 ]\n",
      " [0.849033  ]\n",
      " [0.61185634]\n",
      " [0.7844155 ]\n",
      " [0.36297303]\n",
      " [0.6196606 ]\n",
      " [0.7883094 ]\n",
      " [0.38907346]\n",
      " [0.543617  ]\n",
      " [0.32381475]\n",
      " [0.86531675]\n",
      " [0.1921097 ]\n",
      " [0.40416026]\n",
      " [0.04978544]\n",
      " [0.5297556 ]\n",
      " [0.9255839 ]\n",
      " [0.7282765 ]\n",
      " [0.6878626 ]\n",
      " [0.9476857 ]\n",
      " [0.93785536]\n",
      " [0.9356564 ]\n",
      " [0.2659095 ]\n",
      " [0.33746427]\n",
      " [0.96911645]\n",
      " [0.25154567]\n",
      " [0.34734926]\n",
      " [0.08370849]\n",
      " [0.716858  ]\n",
      " [0.8214868 ]\n",
      " [0.48945427]\n",
      " [0.9163038 ]\n",
      " [0.6976032 ]\n",
      " [0.62676436]\n",
      " [0.8693041 ]\n",
      " [0.5910164 ]\n",
      " [0.4629744 ]\n",
      " [0.962915  ]\n",
      " [0.74426675]\n",
      " [0.847069  ]\n",
      " [0.6822314 ]\n",
      " [0.2504896 ]\n",
      " [0.7831686 ]\n",
      " [0.91329813]\n",
      " [0.94117427]\n",
      " [0.83510387]\n",
      " [0.7935913 ]\n",
      " [0.4205296 ]\n",
      " [0.8881066 ]\n",
      " [0.9292743 ]\n",
      " [0.8980292 ]\n",
      " [0.8512204 ]\n",
      " [0.85478216]\n",
      " [0.3573082 ]\n",
      " [0.79962325]\n",
      " [0.5040126 ]\n",
      " [0.87671924]\n",
      " [0.49031705]\n",
      " [0.91988456]\n",
      " [0.91237676]\n",
      " [0.813603  ]\n",
      " [0.7778975 ]\n",
      " [0.6145572 ]\n",
      " [0.7301483 ]\n",
      " [0.6360124 ]\n",
      " [0.9123485 ]\n",
      " [0.97680056]\n",
      " [0.89254093]\n",
      " [0.5385163 ]\n",
      " [0.18994945]\n",
      " [0.6425298 ]\n",
      " [0.5935934 ]\n",
      " [0.9619199 ]\n",
      " [0.67479515]\n",
      " [0.7293222 ]\n",
      " [0.8600501 ]\n",
      " [0.72215456]\n",
      " [0.91421777]\n",
      " [0.84277064]\n",
      " [0.55652887]\n",
      " [0.4130417 ]\n",
      " [0.92530394]\n",
      " [0.83431166]\n",
      " [0.45775795]\n",
      " [0.38406298]\n",
      " [0.60485506]\n",
      " [0.779334  ]\n",
      " [0.8820927 ]\n",
      " [0.93318105]\n",
      " [0.12034792]\n",
      " [0.73445034]\n",
      " [0.85111785]\n",
      " [0.58229536]\n",
      " [0.6161066 ]\n",
      " [0.75835204]\n",
      " [0.7048327 ]\n",
      " [0.8340101 ]\n",
      " [0.820278  ]\n",
      " [0.52645755]\n",
      " [0.62276334]\n",
      " [0.33449674]\n",
      " [0.4628857 ]\n",
      " [0.7739414 ]\n",
      " [0.9391116 ]\n",
      " [0.8663929 ]\n",
      " [0.78206325]\n",
      " [0.86033225]\n",
      " [0.4146276 ]\n",
      " [0.82217205]\n",
      " [0.69458103]\n",
      " [0.7454815 ]\n",
      " [0.8875117 ]\n",
      " [0.6054866 ]\n",
      " [0.6293926 ]\n",
      " [0.72084755]\n",
      " [0.90248096]\n",
      " [0.6525875 ]\n",
      " [0.42325896]\n",
      " [0.94745183]\n",
      " [0.5872731 ]\n",
      " [0.7377175 ]\n",
      " [0.26335627]\n",
      " [0.3769296 ]\n",
      " [0.13225535]\n",
      " [0.25733107]\n",
      " [0.91214514]\n",
      " [0.8718555 ]\n",
      " [0.9484775 ]\n",
      " [0.11926454]\n",
      " [0.55096954]\n",
      " [0.75584143]\n",
      " [0.6483954 ]\n",
      " [0.872056  ]\n",
      " [0.3780761 ]\n",
      " [0.8130475 ]\n",
      " [0.6906885 ]\n",
      " [0.57306725]\n",
      " [0.6777034 ]\n",
      " [0.8891276 ]\n",
      " [0.7390858 ]\n",
      " [0.6654298 ]\n",
      " [0.8817655 ]\n",
      " [0.8292928 ]\n",
      " [0.9466907 ]\n",
      " [0.22861496]\n",
      " [0.7680888 ]\n",
      " [0.2449657 ]\n",
      " [0.37477005]\n",
      " [0.32408094]\n",
      " [0.8634044 ]\n",
      " [0.7104945 ]\n",
      " [0.9237343 ]\n",
      " [0.8830097 ]\n",
      " [0.5752319 ]\n",
      " [0.18114012]\n",
      " [0.21613738]\n",
      " [0.4942081 ]\n",
      " [0.70708597]\n",
      " [0.65483946]\n",
      " [0.800761  ]\n",
      " [0.5944774 ]\n",
      " [0.35818365]\n",
      " [0.19815463]\n",
      " [0.91968006]\n",
      " [0.4004287 ]\n",
      " [0.8310698 ]\n",
      " [0.9107305 ]\n",
      " [0.64264566]\n",
      " [0.7101743 ]\n",
      " [0.6516977 ]\n",
      " [0.5449943 ]\n",
      " [0.7393092 ]\n",
      " [0.9545456 ]\n",
      " [0.75624794]\n",
      " [0.8312837 ]\n",
      " [0.1674566 ]\n",
      " [0.31826383]\n",
      " [0.89776623]\n",
      " [0.2663147 ]\n",
      " [0.9401423 ]\n",
      " [0.27009904]\n",
      " [0.3234405 ]\n",
      " [0.53647137]\n",
      " [0.7276658 ]\n",
      " [0.21679154]\n",
      " [0.7235019 ]\n",
      " [0.7333076 ]\n",
      " [0.7808437 ]\n",
      " [0.6297736 ]\n",
      " [0.1656053 ]\n",
      " [0.28174698]\n",
      " [0.6894149 ]\n",
      " [0.5082003 ]\n",
      " [0.9272945 ]\n",
      " [0.93823385]\n",
      " [0.67668736]\n",
      " [0.38509172]\n",
      " [0.02800614]\n",
      " [0.6998309 ]\n",
      " [0.326538  ]\n",
      " [0.4756528 ]\n",
      " [0.94287694]\n",
      " [0.5996374 ]\n",
      " [0.9456552 ]\n",
      " [0.22811148]\n",
      " [0.19018763]\n",
      " [0.3474269 ]\n",
      " [0.7167032 ]\n",
      " [0.9169123 ]\n",
      " [0.87268937]\n",
      " [0.62718296]\n",
      " [0.64073974]\n",
      " [0.60910547]\n",
      " [0.18978375]\n",
      " [0.5370723 ]\n",
      " [0.18344742]\n",
      " [0.618441  ]\n",
      " [0.8978073 ]\n",
      " [0.6300378 ]\n",
      " [0.6786545 ]\n",
      " [0.9578949 ]\n",
      " [0.82631046]\n",
      " [0.8024708 ]\n",
      " [0.7342038 ]\n",
      " [0.747167  ]\n",
      " [0.890455  ]\n",
      " [0.50139004]\n",
      " [0.5398374 ]\n",
      " [0.46400216]\n",
      " [0.80825746]\n",
      " [0.72580355]\n",
      " [0.6592005 ]\n",
      " [0.7944447 ]\n",
      " [0.28343463]\n",
      " [0.4260606 ]\n",
      " [0.47899908]\n",
      " [0.6145714 ]\n",
      " [0.3643492 ]\n",
      " [0.89878875]\n",
      " [0.73203945]\n",
      " [0.8816792 ]\n",
      " [0.52850854]\n",
      " [0.68741775]\n",
      " [0.8466605 ]\n",
      " [0.84371614]\n",
      " [0.5847812 ]\n",
      " [0.87957776]\n",
      " [0.35690394]\n",
      " [0.6327115 ]\n",
      " [0.75782025]\n",
      " [0.36998534]\n",
      " [0.76482975]\n",
      " [0.29051566]\n",
      " [0.55391836]\n",
      " [0.9454075 ]\n",
      " [0.7587496 ]\n",
      " [0.8346839 ]\n",
      " [0.6843881 ]\n",
      " [0.4141001 ]\n",
      " [0.6034483 ]\n",
      " [0.398566  ]\n",
      " [0.48274252]\n",
      " [0.6591845 ]\n",
      " [0.65951824]\n",
      " [0.67955303]\n",
      " [0.5254242 ]\n",
      " [0.19631904]\n",
      " [0.69671637]\n",
      " [0.887244  ]\n",
      " [0.4746295 ]\n",
      " [0.61674833]\n",
      " [0.7598808 ]\n",
      " [0.55572283]\n",
      " [0.795527  ]\n",
      " [0.5047521 ]\n",
      " [0.6902874 ]\n",
      " [0.8965599 ]\n",
      " [0.64690965]\n",
      " [0.75778997]\n",
      " [0.8860785 ]\n",
      " [0.5065115 ]\n",
      " [0.8716959 ]\n",
      " [0.9536706 ]\n",
      " [0.31589234]\n",
      " [0.7839267 ]\n",
      " [0.26888463]\n",
      " [0.8233708 ]\n",
      " [0.8325256 ]\n",
      " [0.76666653]\n",
      " [0.37239853]\n",
      " [0.79402006]\n",
      " [0.80412185]\n",
      " [0.7271083 ]\n",
      " [0.2112599 ]\n",
      " [0.81467545]\n",
      " [0.85593784]\n",
      " [0.5459634 ]\n",
      " [0.95130706]\n",
      " [0.26139563]\n",
      " [0.68010557]\n",
      " [0.9550887 ]\n",
      " [0.25327122]\n",
      " [0.39255917]\n",
      " [0.6407743 ]\n",
      " [0.33264583]\n",
      " [0.18891731]\n",
      " [0.8768145 ]\n",
      " [0.9094328 ]\n",
      " [0.85186434]\n",
      " [0.5902924 ]\n",
      " [0.595129  ]\n",
      " [0.5721876 ]\n",
      " [0.79697466]\n",
      " [0.7971071 ]\n",
      " [0.9423088 ]\n",
      " [0.7443881 ]\n",
      " [0.7278604 ]\n",
      " [0.570158  ]\n",
      " [0.9297679 ]\n",
      " [0.9456396 ]\n",
      " [0.64786947]\n",
      " [0.2778112 ]\n",
      " [0.6276828 ]\n",
      " [0.39823565]\n",
      " [0.72725976]\n",
      " [0.2163794 ]\n",
      " [0.3009659 ]\n",
      " [0.40760285]\n",
      " [0.6669029 ]\n",
      " [0.3243502 ]\n",
      " [0.6292919 ]\n",
      " [0.8413346 ]\n",
      " [0.62345684]\n",
      " [0.8818449 ]\n",
      " [0.9531952 ]\n",
      " [0.76770645]\n",
      " [0.05809867]\n",
      " [0.39622706]\n",
      " [0.8379135 ]\n",
      " [0.8466447 ]\n",
      " [0.6174692 ]\n",
      " [0.27527976]\n",
      " [0.90790355]\n",
      " [0.8740793 ]\n",
      " [0.30441356]\n",
      " [0.534123  ]\n",
      " [0.81701815]\n",
      " [0.8817207 ]\n",
      " [0.8708996 ]\n",
      " [0.88276815]\n",
      " [0.8909832 ]\n",
      " [0.9392822 ]\n",
      " [0.6863712 ]\n",
      " [0.6220977 ]\n",
      " [0.58382165]\n",
      " [0.8198137 ]\n",
      " [0.8671799 ]\n",
      " [0.2444781 ]\n",
      " [0.84575975]\n",
      " [0.8969491 ]\n",
      " [0.29333043]\n",
      " [0.5681308 ]\n",
      " [0.8234066 ]\n",
      " [0.59270096]\n",
      " [0.8844125 ]\n",
      " [0.3615451 ]\n",
      " [0.80748963]\n",
      " [0.6160642 ]\n",
      " [0.8864423 ]\n",
      " [0.37701517]\n",
      " [0.70186245]\n",
      " [0.67108643]\n",
      " [0.76608443]\n",
      " [0.08868113]\n",
      " [0.21490446]\n",
      " [0.65079457]\n",
      " [0.8138143 ]\n",
      " [0.47110832]\n",
      " [0.8108827 ]\n",
      " [0.49368638]\n",
      " [0.43910444]\n",
      " [0.8340172 ]\n",
      " [0.48201913]\n",
      " [0.8832396 ]\n",
      " [0.835665  ]\n",
      " [0.63351864]\n",
      " [0.91449714]\n",
      " [0.60201645]\n",
      " [0.8143797 ]\n",
      " [0.3721344 ]\n",
      " [0.3292765 ]\n",
      " [0.7284537 ]\n",
      " [0.4886122 ]\n",
      " [0.46329638]\n",
      " [0.89735246]\n",
      " [0.88075787]\n",
      " [0.9138583 ]\n",
      " [0.9541931 ]\n",
      " [0.67700446]\n",
      " [0.89131427]\n",
      " [0.38159856]\n",
      " [0.42756146]\n",
      " [0.46401376]\n",
      " [0.95070827]\n",
      " [0.5262865 ]\n",
      " [0.24177921]\n",
      " [0.9269235 ]\n",
      " [0.836994  ]\n",
      " [0.49263614]\n",
      " [0.85433877]\n",
      " [0.00996941]\n",
      " [0.92592716]\n",
      " [0.74125206]\n",
      " [0.74352366]\n",
      " [0.8161415 ]\n",
      " [0.96780574]\n",
      " [0.5944566 ]\n",
      " [0.78099227]\n",
      " [0.62649465]\n",
      " [0.85261583]\n",
      " [0.27936667]\n",
      " [0.5418761 ]\n",
      " [0.9075261 ]\n",
      " [0.58593804]\n",
      " [0.7527702 ]\n",
      " [0.9186871 ]\n",
      " [0.7959969 ]\n",
      " [0.88435036]\n",
      " [0.43271345]\n",
      " [0.82599616]\n",
      " [0.9555994 ]\n",
      " [0.72992265]\n",
      " [0.6285022 ]\n",
      " [0.31910777]\n",
      " [0.4603749 ]\n",
      " [0.58435744]\n",
      " [0.6838447 ]\n",
      " [0.50451636]\n",
      " [0.7639512 ]\n",
      " [0.627058  ]\n",
      " [0.7177086 ]\n",
      " [0.85574734]\n",
      " [0.74441993]\n",
      " [0.6520834 ]\n",
      " [0.5453136 ]\n",
      " [0.622174  ]\n",
      " [0.9386281 ]\n",
      " [0.84863305]\n",
      " [0.24551094]\n",
      " [0.45714325]\n",
      " [0.47821254]\n",
      " [0.10751545]\n",
      " [0.9097422 ]\n",
      " [0.14503118]\n",
      " [0.8870903 ]\n",
      " [0.8706566 ]\n",
      " [0.83261275]\n",
      " [0.6704804 ]\n",
      " [0.8666966 ]\n",
      " [0.3409697 ]\n",
      " [0.7459704 ]\n",
      " [0.94136   ]\n",
      " [0.374283  ]\n",
      " [0.4393836 ]\n",
      " [0.88209236]\n",
      " [0.87270576]\n",
      " [0.6057581 ]\n",
      " [0.7993871 ]\n",
      " [0.79814065]\n",
      " [0.76562625]\n",
      " [0.35712874]\n",
      " [0.7595445 ]\n",
      " [0.87275887]\n",
      " [0.5640365 ]\n",
      " [0.80022025]\n",
      " [0.77599216]\n",
      " [0.77121747]\n",
      " [0.8245529 ]\n",
      " [0.9431075 ]\n",
      " [0.69412845]\n",
      " [0.402212  ]\n",
      " [0.74697125]\n",
      " [0.8049867 ]\n",
      " [0.9623451 ]\n",
      " [0.7739793 ]\n",
      " [0.6816529 ]\n",
      " [0.36741352]\n",
      " [0.70481247]\n",
      " [0.9265616 ]\n",
      " [0.9501657 ]\n",
      " [0.920192  ]\n",
      " [0.71960264]\n",
      " [0.6076912 ]\n",
      " [0.8261076 ]\n",
      " [0.42544118]\n",
      " [0.71108544]\n",
      " [0.7508854 ]\n",
      " [0.8503406 ]\n",
      " [0.59933746]\n",
      " [0.67017734]\n",
      " [0.828619  ]\n",
      " [0.47942632]\n",
      " [0.4362727 ]\n",
      " [0.61197186]\n",
      " [0.7489808 ]\n",
      " [0.6204969 ]\n",
      " [0.9115732 ]\n",
      " [0.9156431 ]\n",
      " [0.25296673]\n",
      " [0.15201873]\n",
      " [0.81198674]\n",
      " [0.5008382 ]\n",
      " [0.27363163]\n",
      " [0.8483156 ]\n",
      " [0.8903557 ]\n",
      " [0.64142525]\n",
      " [0.9341811 ]\n",
      " [0.9136789 ]\n",
      " [0.78161985]\n",
      " [0.82661057]\n",
      " [0.6506659 ]\n",
      " [0.58227724]\n",
      " [0.72941804]\n",
      " [0.58109885]\n",
      " [0.16958421]\n",
      " [0.88880444]\n",
      " [0.8910257 ]\n",
      " [0.65919834]\n",
      " [0.9220426 ]\n",
      " [0.8449966 ]\n",
      " [0.88279533]\n",
      " [0.6277669 ]\n",
      " [0.72933066]\n",
      " [0.84819657]\n",
      " [0.6814685 ]\n",
      " [0.85456693]\n",
      " [0.9260819 ]\n",
      " [0.58754206]\n",
      " [0.77582157]\n",
      " [0.83296895]\n",
      " [0.4614274 ]\n",
      " [0.5229118 ]\n",
      " [0.04737052]\n",
      " [0.26203343]\n",
      " [0.8585291 ]\n",
      " [0.7116469 ]\n",
      " [0.6432911 ]\n",
      " [0.58824027]\n",
      " [0.949569  ]\n",
      " [0.448358  ]\n",
      " [0.78509897]\n",
      " [0.26817477]\n",
      " [0.8698143 ]\n",
      " [0.30592662]\n",
      " [0.74175817]\n",
      " [0.52958256]\n",
      " [0.80563456]\n",
      " [0.5306414 ]\n",
      " [0.3456666 ]\n",
      " [0.7438814 ]\n",
      " [0.93418306]\n",
      " [0.39552376]\n",
      " [0.93016124]\n",
      " [0.8884526 ]\n",
      " [0.82872266]\n",
      " [0.82201296]\n",
      " [0.4301162 ]\n",
      " [0.3422479 ]\n",
      " [0.68670404]\n",
      " [0.16458961]\n",
      " [0.94601107]\n",
      " [0.3886749 ]\n",
      " [0.9441322 ]\n",
      " [0.8979254 ]\n",
      " [0.49147138]\n",
      " [0.20255888]\n",
      " [0.6890421 ]\n",
      " [0.47798085]\n",
      " [0.80834734]\n",
      " [0.68478507]\n",
      " [0.98097897]\n",
      " [0.5169099 ]\n",
      " [0.6344462 ]\n",
      " [0.7626096 ]\n",
      " [0.74808407]\n",
      " [0.05669206]\n",
      " [0.7539308 ]\n",
      " [0.76780957]\n",
      " [0.7985194 ]\n",
      " [0.6088046 ]\n",
      " [0.4337113 ]\n",
      " [0.5797603 ]\n",
      " [0.914194  ]\n",
      " [0.56921303]\n",
      " [0.7710574 ]\n",
      " [0.78551555]\n",
      " [0.89400905]\n",
      " [0.78129625]\n",
      " [0.53360337]\n",
      " [0.75546354]\n",
      " [0.9016299 ]\n",
      " [0.66570085]\n",
      " [0.9649066 ]\n",
      " [0.8158053 ]\n",
      " [0.60079366]\n",
      " [0.4776803 ]\n",
      " [0.77550375]\n",
      " [0.830848  ]\n",
      " [0.5409135 ]\n",
      " [0.7241511 ]\n",
      " [0.29499605]\n",
      " [0.5931363 ]\n",
      " [0.8528322 ]\n",
      " [0.9491718 ]\n",
      " [0.8463143 ]\n",
      " [0.72240233]\n",
      " [0.7164912 ]\n",
      " [0.8960395 ]\n",
      " [0.59224486]\n",
      " [0.9279376 ]\n",
      " [0.4476527 ]\n",
      " [0.78352934]\n",
      " [0.3220265 ]\n",
      " [0.08033893]\n",
      " [0.29904458]\n",
      " [0.3230784 ]\n",
      " [0.70375174]\n",
      " [0.80281174]\n",
      " [0.65640396]\n",
      " [0.78467906]\n",
      " [0.7992832 ]\n",
      " [0.56243485]\n",
      " [0.4194888 ]\n",
      " [0.9139849 ]\n",
      " [0.889279  ]\n",
      " [0.38082802]\n",
      " [0.5787075 ]\n",
      " [0.20990768]\n",
      " [0.3879786 ]\n",
      " [0.71865267]\n",
      " [0.6969985 ]\n",
      " [0.9104171 ]\n",
      " [0.97329897]\n",
      " [0.2462126 ]\n",
      " [0.71558213]\n",
      " [0.56426597]\n",
      " [0.37097222]\n",
      " [0.7388618 ]\n",
      " [0.71129584]\n",
      " [0.9151398 ]\n",
      " [0.7280357 ]\n",
      " [0.4598881 ]\n",
      " [0.5735081 ]\n",
      " [0.17170635]\n",
      " [0.65180767]\n",
      " [0.48547575]\n",
      " [0.8878733 ]\n",
      " [0.6521948 ]\n",
      " [0.66079617]\n",
      " [0.7729073 ]\n",
      " [0.7764249 ]\n",
      " [0.39882833]\n",
      " [0.7658165 ]\n",
      " [0.6491721 ]\n",
      " [0.33248317]\n",
      " [0.57322896]\n",
      " [0.9056318 ]\n",
      " [0.8384665 ]\n",
      " [0.57859683]\n",
      " [0.837629  ]\n",
      " [0.30964482]\n",
      " [0.825935  ]\n",
      " [0.71275973]\n",
      " [0.76400113]\n",
      " [0.44664314]\n",
      " [0.71379614]\n",
      " [0.80923414]\n",
      " [0.20503831]\n",
      " [0.2822782 ]\n",
      " [0.8212812 ]\n",
      " [0.7800081 ]\n",
      " [0.7956191 ]\n",
      " [0.9163312 ]\n",
      " [0.77057934]\n",
      " [0.7169509 ]\n",
      " [0.7397573 ]\n",
      " [0.72104764]\n",
      " [0.69203174]\n",
      " [0.7940062 ]\n",
      " [0.5665425 ]\n",
      " [0.4497569 ]\n",
      " [0.8651267 ]\n",
      " [0.8195622 ]\n",
      " [0.62943405]\n",
      " [0.30164403]\n",
      " [0.8833706 ]\n",
      " [0.7472488 ]\n",
      " [0.8413533 ]\n",
      " [0.6763658 ]\n",
      " [0.8799112 ]\n",
      " [0.87420213]\n",
      " [0.7228213 ]\n",
      " [0.39072475]\n",
      " [0.904727  ]\n",
      " [0.92709213]\n",
      " [0.29026163]\n",
      " [0.1515742 ]\n",
      " [0.71312666]\n",
      " [0.41612774]\n",
      " [0.7084857 ]\n",
      " [0.4173672 ]\n",
      " [0.45192987]\n",
      " [0.35455817]\n",
      " [0.76005864]\n",
      " [0.8903239 ]\n",
      " [0.1830273 ]\n",
      " [0.42285076]\n",
      " [0.52673227]\n",
      " [0.50358325]\n",
      " [0.48941714]\n",
      " [0.75764465]\n",
      " [0.16422012]\n",
      " [0.90443003]\n",
      " [0.24159685]\n",
      " [0.8283651 ]\n",
      " [0.67540586]\n",
      " [0.7611738 ]\n",
      " [0.85420287]\n",
      " [0.667159  ]\n",
      " [0.8952562 ]] \n",
      " Correct(y):  [[0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]] \n",
      " Accuracy:  0.7773386\n"
     ]
    }
   ],
   "source": [
    "#Train the model\n",
    "\n",
    "#Launch graph\n",
    "with tf.Session() as sess:\n",
    "    #Initialize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(10001):\n",
    "        cost_val, _ = sess.run([cost, train], feed_dict={x:x_data, y:y_data})\n",
    "        if step % 200 == 0 :\n",
    "            print(step, cost_val)\n",
    "    \n",
    "    #Accuracy report\n",
    "    h, c, a  = sess.run([hypothesis, predicted, accuracy],\n",
    "                       feed_dict={x:x_data, y:y_data})\n",
    "    print('\\n Hypothesis: ', h, '\\n Correct(y): ', c, '\\n Accuracy: ', a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
